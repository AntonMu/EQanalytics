{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOAL\n",
    "The goal of this notebook is to first clean up two location databases, one of all addresses in Oakland, and one of vulnerable buildings. We also use similarity search to match similar street names and cluster similar statuses of buidlings.\n",
    "Secondly, we download the image data to individual folders to enable learning later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up mixed types of house numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def ignore_non_int(df, column = 'NUMBER'):\n",
    "    \"\"\"Returns a df with all rows removed that \n",
    "    do not have integers in 'column'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.Dataframe \n",
    "        The input dataframe that contains\n",
    "        'column'\n",
    "    column : str, optional\n",
    "        The name of the column that should\n",
    "        only contain integers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The dataframe with rows removed\n",
    "    \"\"\"\n",
    "    def to_int(x):\n",
    "        try:\n",
    "            return int(x)\n",
    "        except:\n",
    "            return x\n",
    "    df[column]=df[column].apply(lambda x: to_int(x))\n",
    "    df['dtypes']=df[column].apply(lambda x: type(x))\n",
    "    df=df.loc[df['dtypes']==type(1)]\n",
    "    df.drop('dtypes',axis=1,inplace=True)\n",
    "    df[column]=df[column].apply(lambda x: to_int(x))\n",
    "    return df\n",
    "df_openaddr = pd.read_csv('Locations/alameda.csv')\n",
    "df_openaddr = ignore_non_int(df_openaddr)\n",
    "df_openaddr['NUMBER'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Oakland list of vulnerable buildings and do some pre_processings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcel_number</th>\n",
       "      <th>address</th>\n",
       "      <th>status_long</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>status_short</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>STREET</th>\n",
       "      <th>BUILDING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>022 030500100</td>\n",
       "      <td>2232 IVY DR</td>\n",
       "      <td>Ask for exemption - did not review</td>\n",
       "      <td>37.800755</td>\n",
       "      <td>-122.245017</td>\n",
       "      <td>Exempt</td>\n",
       "      <td>2232</td>\n",
       "      <td>IVY DR</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>027 085401703</td>\n",
       "      <td>2858 BROOKDALE AVE</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>37.793341</td>\n",
       "      <td>-122.217329</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>2858</td>\n",
       "      <td>BROOKDALE AVE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>022 030901400</td>\n",
       "      <td>323 HANOVER AVE</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>37.803079</td>\n",
       "      <td>-122.251108</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>323</td>\n",
       "      <td>HANOVER AVE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010 077102000</td>\n",
       "      <td>246 GRAND AVE</td>\n",
       "      <td>Level 2 - Missing slope</td>\n",
       "      <td>37.809921</td>\n",
       "      <td>-122.258968</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>246</td>\n",
       "      <td>GRAND AVE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>039 330305500</td>\n",
       "      <td>6862 ARTHUR ST</td>\n",
       "      <td>Exempt - less than 5 units</td>\n",
       "      <td>37.765986</td>\n",
       "      <td>-122.182236</td>\n",
       "      <td>Exempt</td>\n",
       "      <td>6862</td>\n",
       "      <td>ARTHUR ST</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcel_number             address                          status_long  \\\n",
       "0  022 030500100         2232 IVY DR  Ask for exemption - did not review    \n",
       "1  027 085401703  2858 BROOKDALE AVE                Incomplete Evaluation   \n",
       "2  022 030901400     323 HANOVER AVE                Incomplete Evaluation   \n",
       "3  010 077102000       246 GRAND AVE              Level 2 - Missing slope   \n",
       "4  039 330305500      6862 ARTHUR ST           Exempt - less than 5 units   \n",
       "\n",
       "    latitude   longitude           status_short NUMBER         STREET BUILDING  \n",
       "0  37.800755 -122.245017                 Exempt   2232         IVY DR     None  \n",
       "1  37.793341 -122.217329  Incomplete Evaluation   2858  BROOKDALE AVE     None  \n",
       "2  37.803079 -122.251108  Incomplete Evaluation    323    HANOVER AVE     None  \n",
       "3  37.809921 -122.258968  Incomplete Evaluation    246      GRAND AVE     None  \n",
       "4  37.765986 -122.182236                 Exempt   6862      ARTHUR ST     None  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seperate_house_numbers(df):\n",
    "    \"\"\"Returns a df that splits the 'address'\n",
    "    column in house number, street number and \n",
    "    building\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.Dataframe \n",
    "        The input dataframe that contains an\n",
    "        'address' column\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The dataframe with seperate columns\n",
    "        for NUMBER, STREET, BUILDING\n",
    "    \"\"\"\n",
    "    #Seperate Street and number\n",
    "    df[['NUMBER','STREET']] = pd.DataFrame(df['address'].str.split(' ',1).tolist(),\n",
    "                                       columns = ['NUMBER','STREET'])\n",
    "    #Seperate Street and building\n",
    "    df[['STREET','BUILDING']]=pd.DataFrame(df['STREET'].str.split(' - ',1).tolist(),\n",
    "                                       columns = ['STREET','BUILDING'])\n",
    "    return df\n",
    "\n",
    "df_vul = seperate_house_numbers(pd.read_csv('Locations/Oakland.csv'))\n",
    "df_vul.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find housenumbers of buildings which were combined, i.e. Telegraph Ave 5678+5683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the odd numbers into seperate columns\n",
    "def tidy_split(df, column, sep='|', keep=False):\n",
    "    \"\"\"\n",
    "    Split the values of a column and expand so the new DataFrame has one split\n",
    "    value per row. Filters rows where the column is missing.\n",
    "    \n",
    "    https://github.com/cognoma/genes/blob/721204091a96e55de6dcad165d6d8265e67e2a48/2.process.py\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as it's own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df\n",
    "\n",
    "\n",
    "df_vul=tidy_split(df_vul,'NUMBER',sep='+')\n",
    "df_vul=ignore_non_int(df_vul)\n",
    "df_vul['NUMBER'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match street names in df_vul with those in df_openaddr via similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcel_number</th>\n",
       "      <th>address</th>\n",
       "      <th>status_long</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>status_short</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>STREET</th>\n",
       "      <th>BUILDING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>022 030500100</td>\n",
       "      <td>2232 IVY DR</td>\n",
       "      <td>Ask for exemption - did not review</td>\n",
       "      <td>37.800755</td>\n",
       "      <td>-122.245017</td>\n",
       "      <td>Exempt</td>\n",
       "      <td>2232</td>\n",
       "      <td>IVY DR</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>027 085401703</td>\n",
       "      <td>2858 BROOKDALE AVE</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>37.793341</td>\n",
       "      <td>-122.217329</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>2858</td>\n",
       "      <td>BROOKDALE AV</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>022 030901400</td>\n",
       "      <td>323 HANOVER AVE</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>37.803079</td>\n",
       "      <td>-122.251108</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>323</td>\n",
       "      <td>HANOVER AV</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010 077102000</td>\n",
       "      <td>246 GRAND AVE</td>\n",
       "      <td>Level 2 - Missing slope</td>\n",
       "      <td>37.809921</td>\n",
       "      <td>-122.258968</td>\n",
       "      <td>Incomplete Evaluation</td>\n",
       "      <td>246</td>\n",
       "      <td>GRAND AV</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>039 330305500</td>\n",
       "      <td>6862 ARTHUR ST</td>\n",
       "      <td>Exempt - less than 5 units</td>\n",
       "      <td>37.765986</td>\n",
       "      <td>-122.182236</td>\n",
       "      <td>Exempt</td>\n",
       "      <td>6862</td>\n",
       "      <td>ARTHUR ST</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcel_number             address                          status_long  \\\n",
       "0  022 030500100         2232 IVY DR  Ask for exemption - did not review    \n",
       "1  027 085401703  2858 BROOKDALE AVE                Incomplete Evaluation   \n",
       "2  022 030901400     323 HANOVER AVE                Incomplete Evaluation   \n",
       "3  010 077102000       246 GRAND AVE              Level 2 - Missing slope   \n",
       "4  039 330305500      6862 ARTHUR ST           Exempt - less than 5 units   \n",
       "\n",
       "    latitude   longitude           status_short  NUMBER        STREET BUILDING  \n",
       "0  37.800755 -122.245017                 Exempt    2232        IVY DR     None  \n",
       "1  37.793341 -122.217329  Incomplete Evaluation    2858  BROOKDALE AV     None  \n",
       "2  37.803079 -122.251108  Incomplete Evaluation     323    HANOVER AV     None  \n",
       "3  37.809921 -122.258968  Incomplete Evaluation     246      GRAND AV     None  \n",
       "4  37.765986 -122.182236                 Exempt    6862     ARTHUR ST     None  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "def align_names(df_1,df_2,column_name = 'STREET'):\n",
    "    \"\"\"Renames all elements in column 'colum_name' of \n",
    "    df_1 to the closest match in  column 'colum_name' \n",
    "    of df_2.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_1 : pd.Dataframe \n",
    "        The dataframe whose column 'column_name'\n",
    "        should be renamed.\n",
    "    df_2 : pd.Dataframe \n",
    "        The input dataframe whose terminology of \n",
    "        column 'column_name' should be applied to \n",
    "        df_1.\n",
    "    column_name: str, optional\n",
    "        The name of the column (must be part of both\n",
    "        dateframes) whose terminology should be\n",
    "        aligned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        df_1 with the column 'column_name' changed to\n",
    "        the closest names of the column 'column_name'\n",
    "        in df_2.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Find all unique elements in column column_name in df_1 and df_2\n",
    "    unique_streets1 = df_1[column_name].unique()\n",
    "    unique_streets2 = df_2[column_name].unique()\n",
    "\n",
    "    # Find most similar entried in column 'column_name' in df_2\n",
    "    matching_streets = []\n",
    "    for unique_street1 in unique_streets1:\n",
    "        matching_streets.append(difflib.get_close_matches(unique_street1, unique_streets2)[0])\n",
    "\n",
    "    #Create a dictionary that can translate names\n",
    "    df1_to_df2 = dict(zip(unique_streets,matching_streets))\n",
    "\n",
    "    # Rename all names column 'column_name' in df_1 to the notation of df_2\n",
    "    df_1[column_name]=df_1[column_name].apply(lambda x: df1_to_df2[x])\n",
    "    \n",
    "    return df_1\n",
    "\n",
    "df_openaddr_oakland = df_openaddr[df_openaddr['CITY']=='OAKLAND']\n",
    "df_vul_matched = align_addresses(df_vul,df_openaddr_oakland)\n",
    "df_vul_matched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we are doing some consistency check of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure most addresses from df_vul_matched are contained in df_openaddr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def address_not_contained(df_1,df_2):\n",
    "    missing = []\n",
    "    for index,row in df_1.iterrows():\n",
    "        if not (((df_2['STREET'] == row['STREET'])\n",
    "                & (df_2['NUMBER'] == row['NUMBER'])).any()):\n",
    "                missing.append(index)\n",
    "    return len(missing)\n",
    "address_not_contained(df_vul_matched,df_openaddr_oakland)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just 33 are missing - that is ok for now. Next we find all streets that have at least 5 vulnerable buildings and find all other buildings in those streets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>STREET</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>CITY</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>REGION</th>\n",
       "      <th>POSTCODE</th>\n",
       "      <th>ID</th>\n",
       "      <th>HASH</th>\n",
       "      <th>Numberlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-122.261672</td>\n",
       "      <td>37.837729</td>\n",
       "      <td>5132</td>\n",
       "      <td>TELEGRAPH AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94609</td>\n",
       "      <td>14-1226-15</td>\n",
       "      <td>2b13400a4d483c21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-122.261910</td>\n",
       "      <td>37.837433</td>\n",
       "      <td>5110</td>\n",
       "      <td>TELEGRAPH AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94609</td>\n",
       "      <td>14-1226-15</td>\n",
       "      <td>fe2c0215b85bd442</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         LON        LAT  NUMBER        STREET UNIT     CITY  \\\n",
       "0           0 -122.261672  37.837729    5132  TELEGRAPH AV  NaN  OAKLAND   \n",
       "1           1 -122.261910  37.837433    5110  TELEGRAPH AV  NaN  OAKLAND   \n",
       "\n",
       "   DISTRICT  REGION  POSTCODE          ID              HASH  Numberlen  \n",
       "0       NaN     NaN     94609  14-1226-15  2b13400a4d483c21          4  \n",
       "1       NaN     NaN     94609  14-1226-15  fe2c0215b85bd442          4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def buildings_in_popular_street(df1,df2,threshold = 5):\n",
    "    \"\"\"Returns those addresses in df2 which are in streets\n",
    "    in df1 that contain more than 'threshold' houses.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df1 : pd.Dataframe \n",
    "        List of addresses with houses for which the number\n",
    "        of buildings per street is determined. \n",
    "     df2 : pd.Dataframe \n",
    "        List of addresses with houses that should be filtered.\n",
    "        This df should contain at least some of the same street\n",
    "        names as df1. \n",
    "    threshold: int, optional\n",
    "        The threshold for the number of houses per street in df1,\n",
    "        that should be used to filter df2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        df2 that contains only those buildings that are in \n",
    "        popular streets (more than threshold buildings) in df1\n",
    "    \"\"\"\n",
    "\n",
    "    counts=pd.DataFrame(df1['STREET'].value_counts(dropna=False))\n",
    "    popular_street = counts[counts>=threshold].dropna().index.tolist()\n",
    "    return df2[df2['STREET'].isin(popular_street)]\n",
    "\n",
    "df_openaddr_oakland_vul_streets = buildings_in_popular_street(df_vul_matched,df_openaddr_oakland)\n",
    "df_openaddr_oakland_vul_streets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function that returns only buildings that are contained in the first, second or in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_which_df(df1,df2,columns = ['STREET','NUMBER'], output = 'first'):\n",
    "    \"\"\"Returns a df with rows only contained in df1 (first), \n",
    "    in both (both), or only in df2 (right) by comparing 'columns'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df1 : pd.Dataframe \n",
    "        The first input dataframe \n",
    "    df2 : pd.Dataframe \n",
    "        The second input dataframe \n",
    "    columns : list of str, optional\n",
    "        The name of the columns where\n",
    "        df1 and df2 should coincide.\n",
    "    output: str, optional\n",
    "        'first': returns rows that are only in df1\n",
    "        'both': returns rows that are both in df1 and df2\n",
    "        'second': returns rows that are only in df2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame of rows that are only in 'output'\n",
    "        \n",
    "    \"\"\"    \n",
    "    df=df1.drop_duplicates().merge(df2.drop_duplicates(),on=columns,\n",
    "                                      how='outer', indicator=True)\n",
    "    if output == 'first':\n",
    "        return df[df['_merge']=='left_only']\n",
    "    elif output == 'second':\n",
    "        return df[df['_merge']=='right_only']\n",
    "    elif output == 'both':\n",
    "        return df[df['_merge']=='both']\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a list of non-vulnerable buildings from streets that contain more than 5 vulnerable buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give us the class '0' (negative) dataset of buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>STREET</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>CITY</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>REGION</th>\n",
       "      <th>POSTCODE</th>\n",
       "      <th>...</th>\n",
       "      <th>HASH</th>\n",
       "      <th>Numberlen</th>\n",
       "      <th>parcel_number</th>\n",
       "      <th>address</th>\n",
       "      <th>status_long</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>status_short</th>\n",
       "      <th>BUILDING</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.261672</td>\n",
       "      <td>37.837729</td>\n",
       "      <td>5132</td>\n",
       "      <td>TELEGRAPH AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94609.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2b13400a4d483c21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-122.261910</td>\n",
       "      <td>37.837433</td>\n",
       "      <td>5110</td>\n",
       "      <td>TELEGRAPH AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94609.0</td>\n",
       "      <td>...</td>\n",
       "      <td>fe2c0215b85bd442</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-122.261959</td>\n",
       "      <td>37.837303</td>\n",
       "      <td>5100</td>\n",
       "      <td>TELEGRAPH AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94609.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5be8273266922da0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         LON        LAT  NUMBER        STREET UNIT     CITY  \\\n",
       "0         0.0 -122.261672  37.837729    5132  TELEGRAPH AV  NaN  OAKLAND   \n",
       "1         1.0 -122.261910  37.837433    5110  TELEGRAPH AV  NaN  OAKLAND   \n",
       "2         3.0 -122.261959  37.837303    5100  TELEGRAPH AV  NaN  OAKLAND   \n",
       "\n",
       "   DISTRICT  REGION  POSTCODE  ...              HASH Numberlen  parcel_number  \\\n",
       "0       NaN     NaN   94609.0  ...  2b13400a4d483c21       4.0            NaN   \n",
       "1       NaN     NaN   94609.0  ...  fe2c0215b85bd442       4.0            NaN   \n",
       "2       NaN     NaN   94609.0  ...  5be8273266922da0       4.0            NaN   \n",
       "\n",
       "  address status_long latitude  longitude  status_short BUILDING     _merge  \n",
       "0     NaN         NaN      NaN        NaN           NaN      NaN  left_only  \n",
       "1     NaN         NaN      NaN        NaN           NaN      NaN  left_only  \n",
       "2     NaN         NaN      NaN        NaN           NaN      NaN  left_only  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_vul_df = in_which_df(df_openaddr_oakland_vul_streets,df_vul_matched,output = 'first')\n",
    "non_vul_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some final clean-up of vulnerable buildings and cluster them by their statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Done - Level 1', 'Done - Level 1 '],\n",
       " ['Incomplete Evaluation', 'Incomplete Evaluation - no data']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar_clusters(df, column_name,cutoff=.8):\n",
    "    \"\"\"Returns a clusters of similar terms in column_name of the\n",
    "    DataFrame df. The cut_off variable determines the threshold\n",
    "    for similarity\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.Dataframe \n",
    "        The input dataframe with a column 'column_name'\n",
    "    column_name : str\n",
    "        The name of the columns of categories to be clustered\n",
    "    cutoff : float, optional\n",
    "        Value betweeen 0 and 1 that gives the similarity threshol\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of list of expressions that are similar.\n",
    "        \n",
    "    \"\"\"   \n",
    "    #     Make a list of all unique items in column\n",
    "    cats = list(pd.DataFrame(df[column_name].value_counts()).index)\n",
    "\n",
    "    # Find similar clusters\n",
    "    logical_sets = []\n",
    "    for cat in cats:\n",
    "        cluster = difflib.get_close_matches(cat, cats, n=10, cutoff=0.8)\n",
    "        cluster.sort()\n",
    "        logical_sets.append(cluster)\n",
    "\n",
    "        # Delete duplicates\n",
    "    unique_list = []\n",
    "    for logical_set in logical_sets:\n",
    "        if not logical_set in unique_list:\n",
    "            unique_list.append(logical_set)\n",
    "    return unique_list\n",
    "df_vul_clusters = find_similar_clusters(df_vul_matched, column_name ='status_long')\n",
    "df_vul_clusters[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Street View Images for Datasets via Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "def download_images(df,api_key='', dir_path ='images',class_name = 'vulnerable', \n",
    "                    title = 'view', category = '',pitch=10):\n",
    "    \"\"\"Downloads all Street view for all rows with addresses in df. \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.Dataframe \n",
    "        The df with rows that contain at least the columns\n",
    "        'CITY', 'STREET', 'NUMBER', 'LAT', 'LON'\n",
    "    api_key : str, optional\n",
    "        Google Maps Street View API key, without the key only \n",
    "        the request url is returned\n",
    "    dir_path : str, optional\n",
    "        The path of the download folder\n",
    "    class_name : str, optional\n",
    "        The label of the data to download\n",
    "    title : str, optional\n",
    "        The name of the image file\n",
    "    category : str, optional\n",
    "        An additional layer of nesting within\n",
    "        the class\n",
    "    pitch : int, optional\n",
    "        the camera angle of the street view image,\n",
    "        0 is horizontal\n",
    "    output: str, optional\n",
    "        'first': returns rows that are only in df1\n",
    "        'both': returns rows that are both in df1 and df2\n",
    "        'second': returns rows that are only in df2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Downloads all images to their respective folders as jpg \n",
    "    and saves all other info in a json file with the same name.\n",
    "    returns True once completed. \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def empty_str(x):\n",
    "        if str(x)=='nan':\n",
    "            return ''\n",
    "        else:\n",
    "            return x\n",
    "    total_path = ('/').join([dir_path,class_name])\n",
    "    if not path.isdir(total_path):\n",
    "        makedirs(total_path)\n",
    "    if category:\n",
    "            category = category.replace(' ','-').replace('/','-')\n",
    "            total_path=('/').join([total_path,category])\n",
    "            if not path.isdir(total_path):\n",
    "                makedirs(total_path)\n",
    "        \n",
    "        \n",
    "    for index,row in df.iterrows():\n",
    "        address_str = ('+').join([str(row['NUMBER']),\n",
    "                                        row['STREET'],\n",
    "                                        row['CITY'],\n",
    "                                            ]).replace(' ','+')\n",
    "        try:\n",
    "            unit = empty_str(row['UNIT'])\n",
    "            address_str+='+'+unit\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            postcode = str(row['POSTCODE'])\n",
    "            address_str+='+'+postcode\n",
    "        except:\n",
    "            pass                                 \n",
    "        file_name = ('_').join([title,\n",
    "                                class_name,\n",
    "                                str(int(time.time())),\n",
    "                                \"{:+f}\".format(row['LAT']),\n",
    "                                \"{:+f}\".format(row['LON']),\n",
    "                                str(pitch),\n",
    "                                address_str\n",
    "                               ]) \n",
    "        if category:\n",
    "            file_name+='+'+category\n",
    "\n",
    "        url='https://maps.googleapis.com/maps/api/streetview?source=outdoor&size=640x640'\n",
    "        url+= '&pitch='+str(pitch)\n",
    "        url+= '&key='+api_key\n",
    "        url+= '&location='+address_str\n",
    "        if not api_key:\n",
    "            return url\n",
    "        response = requests.get(url)\n",
    "        file_path = path.join(total_path,file_name)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path+\".jpg\", 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            with open(file_path+\".json\", 'w') as f:\n",
    "                f.write(str(row.to_json()))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Non-vulnerable buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_images(non_vul_df,class_name='non_vulnerable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download vulnerable buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the diffent categorical clusters of df_vul_matched and download images into separate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current category Done - Level 1\n",
      "current category Incomplete Evaluation\n",
      "current category Incomplete Evaluation - Unclaimed\n",
      "current category Done - Level 2 Required\n",
      "current category Exempt - engineer's letter\n",
      "current category Exempt - no large openings\n",
      "current category Level 1 - missing data\n",
      "current category Level 2 - Missing slope\n",
      "current category Exempt - less than 5 units\n",
      "current category Exempt - retrofitted\n",
      "current category Ask for exemption - did not review\n",
      "current category Exempt - city inspection\n",
      "current category Done - Level 2 in process\n",
      "current category Exempt - no parking/commercial\n",
      "current category Incomplete Evaluation\n",
      "current category Done - Level 2 in process - requires retrofit\n",
      "current category Exempt - Garage In basement\n",
      "current category Exempt - built after 1990\n"
     ]
    }
   ],
   "source": [
    "# First rename some columns and set city name\n",
    "df_vul_matched=df_vul_matched.rename(index=str, columns={\"latitude\": \"LAT\", \"longitude\": \"LON\"})\n",
    "df_vul_matched['CITY']='OAKLAND'\n",
    "\n",
    "for cluster in df_vul_clusters:\n",
    "    print('current category', item[0])\n",
    "    download_images(df_vul_matched[df_vul_matched['status_long'].isin(cluster)],\n",
    "                           class_name='vulnerable',\n",
    "                           category = item[0],test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All done - we got our positive and negative training dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
